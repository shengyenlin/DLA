{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc\n",
    "import time\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "SEED = 1234\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherTrainingDataset(Dataset):\n",
    "    def __init__(self, X, y, augment = None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.augment is not None:\n",
    "            img = self.augment(self.X[idx])\n",
    "        else:\n",
    "            img = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        return img, label\n",
    "\n",
    "class WeatherTestingDataset(Dataset):\n",
    "    def __init__(self, X, augment = None):\n",
    "        self.X = X\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.augment is not None:\n",
    "            img = self.augment(self.X[idx])\n",
    "        else:\n",
    "            img = self.X[idx]\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherRegrssionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WeatherRegrssionNet, self).__init__()\n",
    "\n",
    "        ###########################general information###########################\n",
    "        self.conv1_out_channels = 64\n",
    "        self.leakyReLU1_slope = 0.05\n",
    "        self.conv1_dropout_rate = 0.2\n",
    "\n",
    "        self.conv0 = nn.Sequential(\n",
    "            nn.Conv2d(13, self.conv1_out_channels, kernel_size=5, padding=2),\n",
    "            nn.LeakyReLU(negative_slope=self.leakyReLU1_slope),\n",
    "            nn.BatchNorm2d(self.conv1_out_channels),\n",
    "            nn.Dropout2d(0.2)\n",
    "        )\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(self.conv1_out_channels, self.conv1_out_channels, kernel_size=5, padding=2),\n",
    "            nn.LeakyReLU(negative_slope=self.leakyReLU1_slope),\n",
    "            nn.BatchNorm2d(self.conv1_out_channels),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.25)\n",
    "        )\n",
    "\n",
    "        #########################location information######################\n",
    "        self.conv2_out_channels = 512\n",
    "        self.leakyReLU2_slope = 0.05\n",
    "        self.conv2_dropout_rate = 0.5\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(self.conv1_out_channels, 128, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=self.leakyReLU2_slope),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.3)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, self.conv2_out_channels, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=self.leakyReLU2_slope),\n",
    "            nn.BatchNorm2d(self.conv2_out_channels),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.4)\n",
    "        )\n",
    "        #######################Fully connected layer########################\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(3*4*self.conv2_out_channels, self.conv2_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.conv2_out_channels),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(self.conv2_out_channels, self.conv2_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.conv2_out_channels),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "        self.fc3 = nn.Linear(self.conv2_out_channels, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(-1, 3*4*self.conv2_out_channels)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "def train(train_loader, model, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    for (img, label) in train_loader:\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(img)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()            \n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        #release memory\n",
    "        del img, label, output, loss\n",
    "        torch.cuda.empty_cache()\n",
    "    train_loss = np.mean(train_loss)\n",
    "    return train_loss\n",
    "    \n",
    "    \n",
    "def valid(valid_loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = []\n",
    "        valid_acc = []\n",
    "        for (img, label) in valid_loader:\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(img)\n",
    "            loss = loss_fn(output, label)\n",
    "            valid_loss.append(loss.item())\n",
    "            #release memory\n",
    "            del img, label, output, loss\n",
    "            torch.cuda.empty_cache()\n",
    "    #average over all batches\n",
    "    valid_loss = np.mean(valid_loss)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader, model, device, isValid = False, isTesting = False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predict_result = []\n",
    "        if isValid:\n",
    "            for (img, label) in data_loader:\n",
    "                img = img.to(device)\n",
    "                output = model(img).cpu().detach().numpy()\n",
    "                predict_result.extend(output)\n",
    "        if isTesting:\n",
    "            for img in data_loader:\n",
    "                img = img.to(device)\n",
    "                output = model(img).cpu().detach().numpy()\n",
    "                predict_result.extend(output)\n",
    "    return predict_result\n",
    "\n",
    "def write_to_csv(predict_result, file_name):\n",
    "    with open(file_name, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['INDEX', 'PM2.5-1', 'PM2.5-2'])\n",
    "        for i in range(len(predict_result)):\n",
    "            writer.writerow([str(i+1), str(predict_result[i][0]), str(predict_result[i][1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherTrainingRNNDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        return X, y\n",
    "\n",
    "class WeatherTestingRNNDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherLstmNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(WeatherLstmNet, self).__init__()\n",
    "        self.num_layers = num_layers \n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True, dropout = 0.3)\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.fc2 = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size)).to(device).double()\n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size)).to(device).double()\n",
    "            \n",
    "        # Propagate input through LSTM\n",
    "        out, (h_out, c_out) = self.lstm(x, (h_0, c_0)) \n",
    "        out = out[:, -1, :] #(batch_size, hidden_size x D)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "- Load CNN model and predict result\n",
    "- data preprocessing\n",
    "- train RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../data/training_x_grid.npy')\n",
    "X_test = np.load('../data/testing_x_grid.npy')\n",
    "y_train = np.load('../data/training_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_img = np.mean(X_train, axis=(0, 1, 2))\n",
    "std_img = np.std(X_train, axis=(0, 1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict by CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model_path = \"b06702064_ShengYenLin_CNN.pth\"\n",
    "checkpoint = torch.load(CNN_model_path)\n",
    "CNN_model = WeatherRegrssionNet()\n",
    "CNN_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "CNN_model.to(device)\n",
    "CNN_model = CNN_model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=mean_img, std=std_img)\n",
    "                ])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "#predict training set\n",
    "train_dataset = WeatherTrainingDataset(X_train, y_train, image_transforms)\n",
    "data_loader_CNN = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)  \n",
    "y_pred_train = predict(data_loader_CNN, CNN_model, device, isValid = True)\n",
    "y_pred_train = np.array(y_pred_train)\n",
    "\n",
    "#predict testing set\n",
    "test_dataset_CNN = WeatherTestingDataset(X_test, image_transforms)\n",
    "test_loader_CNN = DataLoader(test_dataset_CNN, batch_size=batch_size, shuffle=False) \n",
    "y_pred_test = predict(test_loader_CNN, CNN_model, device, isTesting = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize RNN dataset\n",
    "SS = StandardScaler()\n",
    "y_pred_train_SS = SS.fit_transform(y_pred_train)\n",
    "y_pred_test_SS = SS.transform(y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare RNN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 8\n",
    "X_train_RNN, X_test_RNN = ([] for _ in range(2))\n",
    "\n",
    "for i in range(y_pred_train_SS.shape[0]-time_step):\n",
    "    X_train_RNN.append(y_pred_train_SS[i:i+time_step])\n",
    "    X_test_RNN.append(y_pred_test_SS[i:i+time_step])\n",
    "X_train_RNN = np.array(X_train_RNN)\n",
    "X_test_RNN  = np.array(X_test_RNN)\n",
    "y_train_RNN = y_train[time_step:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data set\n",
    "test_ratio = 0.25\n",
    "X_train_RNN, X_valid_RNN, y_train_RNN, y_valid_RNN = train_test_split(X_train_RNN, y_train_RNN, test_size = test_ratio)\n",
    "train_dataset_RNN = WeatherTrainingRNNDataset(X_train_RNN, y_train_RNN)\n",
    "valid_dataset_RNN = WeatherTrainingRNNDataset(X_valid_RNN, y_valid_RNN)\n",
    "test_dataset_RNN = WeatherTestingRNNDataset(X_test_RNN)\n",
    "#Data loader\n",
    "batch_size = 128\n",
    "train_loader_RNN = DataLoader(train_dataset_RNN, batch_size=batch_size, shuffle=True)\n",
    "valid_loader_RNN = DataLoader(valid_dataset_RNN, batch_size=batch_size, shuffle=False)  \n",
    "test_loader_RNN = DataLoader(test_dataset_RNN, batch_size=batch_size, shuffle=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict by RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2 #number of features\n",
    "hidden_size = 512 #number of weight in hidden layer\n",
    "num_layers = 2 #number of stacked LSTM layer\n",
    "\n",
    "RNN_model_path = \"b06702064_ShengYenLin_RNN.pth\"\n",
    "checkpoint = torch.load(RNN_model_path)\n",
    "RNN_model = WeatherLstmNet(input_size, hidden_size, num_layers)\n",
    "RNN_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "RNN_model.to(device)\n",
    "RNN_model = RNN_model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RNN = predict(test_loader_RNN, RNN_model, device, isTesting = True)\n",
    "write_to_csv(y_pred_RNN, 'b06702064_ShengYenLin_final_test.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "853a6c1de715781c4e36e93313002732d37040606184d41a7b9ff831089b66e5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('EEML': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
