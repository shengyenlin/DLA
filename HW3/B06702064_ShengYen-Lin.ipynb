{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "SEED = 1234\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(data, timestep, data_type = 'x'):\n",
    "    query_dim = 2\n",
    "    if data_type == 'x':\n",
    "        assert data.ndim == query_dim #number of array dimensions\n",
    "        return (\n",
    "            np.array(\n",
    "                [data[i:i+timestep] for i in range(data.shape[0]-(2*timestep))]\n",
    "                )\n",
    "            )\n",
    "    elif data_type == 'y':\n",
    "        assert data.ndim == query_dim\n",
    "        return (np.array([data[i+timestep:i+(2*timestep)] for i in range(data.shape[0]-(2*timestep))]))\n",
    "    else:\n",
    "        print('incorrect data type')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, X, y, mode):\n",
    "        self.mode = mode\n",
    "        if mode in [\"train\", \"valid\"]:\n",
    "            self.data = torch.from_numpy(X).float()\n",
    "            self.target = torch.from_numpy(y).float()\n",
    "        else:\n",
    "            self.data = torch.from_numpy(X).float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode in [\"train\", \"valid\"]:\n",
    "            return self.data[index], self.target[index]\n",
    "        else:\n",
    "            return self.data[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, rnn_num_layers=1, input_feature_len=1, \n",
    "        sequence_len=168, hidden_size=100, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.sequence_len = sequence_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_feature_len = input_feature_len\n",
    "        self.num_layers = rnn_num_layers\n",
    "        self.rnn_directions = 2 if bidirectional else 1\n",
    "        self.gru = nn.GRU(\n",
    "            num_layers = rnn_num_layers,\n",
    "            input_size=input_feature_len,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_seq, device):\n",
    "        #(D * num_layers, N, hidden_size)\n",
    "        #first dim: 1-LSTM ->, 1-LSTM <-, 2-LSTM ->, 2-LSTM, ...\n",
    "        ht = torch.zeros(\n",
    "            self.num_layers * self.rnn_directions, \n",
    "            input_seq.size(0) , self.hidden_size).to(device)\n",
    "\n",
    "        #out: (N, L, D*H)\n",
    "        #hidden: (D*num_layers, N, H)\n",
    "        gru_out, hidden = self.gru(input_seq, ht)\n",
    "        if self.rnn_directions > 1:\n",
    "            #view = reshape\n",
    "            #reshape to (N, seq_len, D, H) and sum D[0], D[1], ...\n",
    "            gru_out = gru_out.view(\n",
    "                input_seq.size(0), self.sequence_len, \n",
    "                self.rnn_directions, self.hidden_size)\n",
    "            #sum the value of bi-LSTM output layer\n",
    "            print(gru_out.shape)\n",
    "            a, b = gru_out[:, :, -2], gru_out[:, :, -1]\n",
    "            gru_out = torch.cat((a,b), 2)\n",
    "            c, d = hidden[-2], hidden[-1]\n",
    "            hidden = torch.cat((c,d),1)\n",
    "        #print(gru_out.shape)\n",
    "        #print(hidden.shape)\n",
    "        #out: (N, L)\n",
    "        #hidden: (N, H*2)\n",
    "        return gru_out, hidden.squeeze(0)\n",
    "\n",
    "#squeeze: Returns a tensor with all the dimensions of input of size 1 removed\n",
    "    \n",
    "class AttentionDecoderCell(nn.Module):\n",
    "    def __init__(self, input_feature_len, hidden_size, sequence_len):\n",
    "        super().__init__()\n",
    "        # attention_inputs - (decoder_inputs, prev_hidden)\n",
    "        self.attention_linear = nn.Linear(\n",
    "            hidden_size + input_feature_len, \n",
    "            sequence_len)\n",
    "        # attention_combine - inputs - (decoder_inputs, attention * encoder_outputs)\n",
    "        self.decoder_rnn_cell = nn.GRUCell(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "        )\n",
    "        self.out = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, encoder_output, prev_hidden, decoder_input):\n",
    "        #encoder_output: (N, L, H)\n",
    "        #prev_hidden: from encoder hidden layer, (N, H)\n",
    "        #decoder_input: (N, 1)\n",
    "        attention_input = torch.cat(\n",
    "            #first prev_hidden is from the hidden layer of encoder\n",
    "            (prev_hidden, decoder_input), \n",
    "            axis=1) \n",
    "        attention_weights = F.softmax(\n",
    "            self.attention_linear(attention_input),\n",
    "            dim = 1\n",
    "            ).unsqueeze(1) #attention_weights: (N, 1, L)\n",
    "\n",
    "        #bmm = batch matrix-matrix product\n",
    "        #attention_combine: (N, 1, H) -> (N, H)\n",
    "        attention_combine = torch.bmm(\n",
    "            attention_weights, encoder_output\n",
    "            ).squeeze(1) #attention在encoder ouput上\n",
    "        #print(attention_combine.shape)\n",
    "        rnn_hidden = self.decoder_rnn_cell(attention_combine, prev_hidden) #input, h\n",
    "        output = self.out(rnn_hidden)\n",
    "        return output, rnn_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, encoder, decoder, encoder_optimizer, decoder_optimizer, \n",
    "    criterion, predict_time_steps, teacher_forcing_prob, device):\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    loss = 0\n",
    "\n",
    "    for (input_seq, label) in train_loader:\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        encoder_output, encoder_hidden = encoder(input_seq, device)\n",
    "        prev_hidden = encoder_hidden\n",
    "\n",
    "        outputs = torch.zeros(input_seq.size(0), predict_time_steps)\\\n",
    "            .to(device) #store output\n",
    "        decoder_input = DUMMY_INPUT.repeat(input_seq.size(0)).unsqueeze(1).float()\\\n",
    "            .to(device) #dummy starting input\n",
    "\n",
    "        use_teacher_forcing = torch.rand(1) < teacher_forcing_prob\n",
    "        #predict by time step by time step\n",
    "        for i in range(predict_time_steps):\n",
    "            if (label is not None) and (i > 0) and use_teacher_forcing:\n",
    "                decoder_input = label[:, i] #ground truth: (N, 1)\n",
    "            \n",
    "            decoder_output, prev_hidden = decoder(\n",
    "                encoder_output, prev_hidden, decoder_input\n",
    "                    )\n",
    "            \n",
    "            decoder_input = decoder_output #output from GRUCell, (N, 1)\n",
    "            outputs[:, i] = decoder_output.squeeze(1)\n",
    "        loss += criterion(outputs, label.squeeze(2)) \n",
    "\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    return loss / (len(train_loader.dataset) * input_seq.size(1))\n",
    "\n",
    "def valid(\n",
    "    valid_loader, encoder, decoder, \n",
    "    criterion, predict_time_steps, device\n",
    "    ):\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for (input_seq, label) in valid_loader:\n",
    "            encoder_output, encoder_hidden = encoder(input_seq, device)\n",
    "            prev_hidden = encoder_hidden\n",
    "\n",
    "            outputs = torch.zeros(input_seq.size(0), predict_time_steps)\\\n",
    "                .to(device) #store output\n",
    "            decoder_input = DUMMY_INPUT.repeat(input_seq.size(0)).unsqueeze(1).float()\\\n",
    "                .to(device) #dummy starting input\n",
    "\n",
    "            #predict by time step by time step\n",
    "            for i in range(predict_time_steps):\n",
    "                decoder_output, prev_hidden = decoder(\n",
    "                    encoder_output, prev_hidden, decoder_input\n",
    "                        )\n",
    "                decoder_input = decoder_output #output from GRUCell, (N, 1)\n",
    "                outputs[:, i] = decoder_output.squeeze(1)\n",
    "            loss += criterion(outputs, label.squeeze(2))\n",
    "    return loss / (len(valid_loader.dataset) * input_seq.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "    train_loader, valid_loader, encoder, decoder, patience,\n",
    "    epoch_num, encoder_optimizer, decoder_optimizer, criterion\n",
    "    ):\n",
    "\n",
    "    best_loss = np.inf\n",
    "    best_encoder = None\n",
    "    best_decoder = None\n",
    "    no_update_cnt = 0\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(epoch_num):\n",
    "        train_loss = train(\n",
    "            train_loader, encoder, decoder, encoder_optimizer, decoder_optimizer, \n",
    "            criterion, predict_time_steps, teacher_forcing_prob, device)\n",
    "        valid_loss = valid(\n",
    "            valid_loader, encoder, decoder, \n",
    "            criterion, predict_time_steps, device)\n",
    "\n",
    "        end = time.time()\n",
    "        elapsed_minutes = (end - start) / 60\n",
    "        print('Epoch {:} [Train] loss:{:.3f} /'.\\\n",
    "            format(epoch+1, train_loss), end = \" \")\n",
    "        print('[Valid] loss:{:.3f} , {:.2f} minutes elapsed'.\\\n",
    "            format(valid_loss, elapsed_minutes))\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_encoder = copy.deepcopy(encoder)\n",
    "            best_decoder = copy.deepcopy(decoder)\n",
    "        else:\n",
    "            no_update_cnt += 1\n",
    "        \n",
    "        if no_update_cnt == patience:\n",
    "            print(\"Result: best valid loss {:.3f}\".format(best_loss))\n",
    "            return best_encoder, best_decoder\n",
    "\n",
    "    print(\"Result: best valid loss {:.3f}\".format(best_loss))\n",
    "    return best_encoder, best_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_testing(test_loader, encoder, decoder, predict_time_steps, device, output_path):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    num_iter = 0\n",
    "    final_matrix = None\n",
    "    with torch.no_grad():\n",
    "        for input_seq in test_loader:\n",
    "            encoder_output, encoder_hidden = encoder(input_seq, device)\n",
    "            prev_hidden = encoder_hidden\n",
    "\n",
    "            outputs = torch.zeros(input_seq.size(0), predict_time_steps)\\\n",
    "                .to(device) \n",
    "            decoder_input = DUMMY_INPUT.repeat(input_seq.size(0)).unsqueeze(1).float()\\\n",
    "                .to(device)\n",
    "\n",
    "            for i in range(predict_time_steps):\n",
    "                decoder_output, prev_hidden = decoder(\n",
    "                    encoder_output, prev_hidden, decoder_input\n",
    "                        )\n",
    "                decoder_input = decoder_output\n",
    "                outputs[:, i] = decoder_output.squeeze(1)\n",
    "            \n",
    "            if num_iter == 0:\n",
    "                final_matrix = outputs.cpu().detach().numpy()\n",
    "            else:\n",
    "                final_matrix = np.concatenate(\n",
    "                    [final_matrix, outputs.cpu().detach().numpy()],\n",
    "                    axis = 0\n",
    "                )\n",
    "            num_iter += 1\n",
    "    idx_arr = np.arange(1, final_matrix.shape[0]+1, dtype = int)\n",
    "    final_matrix = np.concatenate(\n",
    "        [idx_arr.reshape(-1, 1), final_matrix],\n",
    "        axis = 1\n",
    "    )\n",
    "    final_df = pd.DataFrame(final_matrix)\n",
    "    final_df.columns = ['INDEX', 'PM2.5-1','PM2.5-2', 'PM2.5-3', 'PM2.5-4',\n",
    "        'PM2.5-5', 'PM2.5-6', 'PM2.5-7', 'PM2.5-8']\n",
    "    final_df[\"INDEX\"] = final_df[\"INDEX\"].astype(\"Int32\") \n",
    "    final_df.to_csv(output_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 8\n",
    "X_train = np.load('./data/training_x.npy')\n",
    "X_test = np.load('./data/testing_x.npy')\n",
    "y_train = np.load('./data/training_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS = StandardScaler()\n",
    "X_train_norm = SS.fit_transform(X_train)\n",
    "X_test_norm = SS.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8744, 8, 13) (8744, 8, 13)\n",
      "(8744, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_shift = make_data(X_train_norm, timestep, data_type = 'x')\n",
    "X_test_shift = make_data(X_test_norm, timestep, data_type = 'x')\n",
    "print(X_train_shift.shape, X_test_shift.shape)\n",
    "\n",
    "y_train_shift = make_data(y_train, timestep, data_type = 'y')\n",
    "print(y_train_shift.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_ratio = 0.2\n",
    "X_train_shift, X_valid_shift, y_train_shift, y_valid_shift = train_test_split(\n",
    "    X_train_shift, y_train_shift, test_size = train_valid_ratio, random_state = SEED\n",
    ")\n",
    "\n",
    "DUMMY_INPUT = torch.tensor(\n",
    "    y_train.mean()\n",
    ")\n",
    "\n",
    "train_dataset = WeatherDataset(\n",
    "    X_train_shift, y_train_shift, \"train\"\n",
    ")\n",
    "valid_dataset = WeatherDataset(\n",
    "    X_valid_shift, y_valid_shift, \"valid\"\n",
    ")\n",
    "test_dataset = WeatherDataset(\n",
    "    X_test_shift, None, \"test\"\n",
    ")\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size, shuffle = True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, batch_size, shuffle = False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size, shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train] loss:885.309 / [Valid] loss:740.405 , 0.32 minutes elapsed\n",
      "Epoch 2 [Train] loss:739.918 / [Valid] loss:312.802 , 0.63 minutes elapsed\n",
      "Epoch 3 [Train] loss:326.920 / [Valid] loss:218.914 , 0.96 minutes elapsed\n",
      "Epoch 4 [Train] loss:230.301 / [Valid] loss:230.504 , 1.28 minutes elapsed\n",
      "Epoch 5 [Train] loss:240.726 / [Valid] loss:254.853 , 1.61 minutes elapsed\n",
      "Epoch 6 [Train] loss:285.525 / [Valid] loss:211.730 , 1.92 minutes elapsed\n",
      "Epoch 7 [Train] loss:220.571 / [Valid] loss:210.168 , 2.24 minutes elapsed\n",
      "Epoch 8 [Train] loss:218.063 / [Valid] loss:214.013 , 2.56 minutes elapsed\n",
      "Epoch 9 [Train] loss:221.088 / [Valid] loss:216.944 , 2.89 minutes elapsed\n",
      "Epoch 10 [Train] loss:223.542 / [Valid] loss:214.637 , 3.21 minutes elapsed\n",
      "Epoch 11 [Train] loss:220.311 / [Valid] loss:212.072 , 3.53 minutes elapsed\n",
      "Epoch 12 [Train] loss:218.076 / [Valid] loss:209.766 , 3.85 minutes elapsed\n",
      "Epoch 13 [Train] loss:217.412 / [Valid] loss:209.427 , 4.17 minutes elapsed\n",
      "Epoch 14 [Train] loss:217.771 / [Valid] loss:209.486 , 4.49 minutes elapsed\n",
      "Epoch 15 [Train] loss:217.881 / [Valid] loss:209.261 , 4.81 minutes elapsed\n",
      "Epoch 16 [Train] loss:217.827 / [Valid] loss:208.490 , 5.15 minutes elapsed\n",
      "Epoch 17 [Train] loss:217.174 / [Valid] loss:209.911 , 5.48 minutes elapsed\n",
      "Epoch 18 [Train] loss:217.867 / [Valid] loss:216.094 , 5.80 minutes elapsed\n",
      "Epoch 19 [Train] loss:217.577 / [Valid] loss:217.637 , 6.13 minutes elapsed\n",
      "Epoch 20 [Train] loss:217.751 / [Valid] loss:220.518 , 6.46 minutes elapsed\n",
      "Epoch 21 [Train] loss:218.097 / [Valid] loss:217.870 , 6.78 minutes elapsed\n",
      "Epoch 22 [Train] loss:216.609 / [Valid] loss:207.824 , 7.10 minutes elapsed\n",
      "Epoch 23 [Train] loss:211.609 / [Valid] loss:200.214 , 7.42 minutes elapsed\n",
      "Epoch 24 [Train] loss:207.836 / [Valid] loss:196.239 , 7.74 minutes elapsed\n",
      "Epoch 25 [Train] loss:204.820 / [Valid] loss:193.647 , 8.06 minutes elapsed\n",
      "Epoch 26 [Train] loss:202.273 / [Valid] loss:190.831 , 8.38 minutes elapsed\n",
      "Epoch 27 [Train] loss:199.675 / [Valid] loss:186.923 , 8.70 minutes elapsed\n",
      "Epoch 28 [Train] loss:196.314 / [Valid] loss:183.108 , 9.03 minutes elapsed\n",
      "Epoch 29 [Train] loss:192.977 / [Valid] loss:179.653 , 9.36 minutes elapsed\n",
      "Epoch 30 [Train] loss:189.430 / [Valid] loss:176.259 , 9.68 minutes elapsed\n",
      "Epoch 31 [Train] loss:185.908 / [Valid] loss:172.098 , 10.01 minutes elapsed\n",
      "Epoch 32 [Train] loss:182.339 / [Valid] loss:168.644 , 10.34 minutes elapsed\n",
      "Epoch 33 [Train] loss:178.703 / [Valid] loss:165.418 , 10.66 minutes elapsed\n",
      "Epoch 34 [Train] loss:175.278 / [Valid] loss:161.424 , 10.98 minutes elapsed\n",
      "Epoch 35 [Train] loss:171.937 / [Valid] loss:158.058 , 11.31 minutes elapsed\n",
      "Epoch 36 [Train] loss:168.266 / [Valid] loss:154.459 , 11.68 minutes elapsed\n",
      "Epoch 37 [Train] loss:164.848 / [Valid] loss:151.255 , 12.03 minutes elapsed\n",
      "Epoch 38 [Train] loss:161.917 / [Valid] loss:149.548 , 12.36 minutes elapsed\n",
      "Epoch 39 [Train] loss:158.855 / [Valid] loss:144.588 , 12.69 minutes elapsed\n",
      "Epoch 40 [Train] loss:154.784 / [Valid] loss:140.819 , 13.01 minutes elapsed\n",
      "Epoch 41 [Train] loss:150.561 / [Valid] loss:136.594 , 13.32 minutes elapsed\n",
      "Epoch 42 [Train] loss:146.465 / [Valid] loss:133.484 , 13.65 minutes elapsed\n",
      "Epoch 43 [Train] loss:142.760 / [Valid] loss:131.343 , 13.97 minutes elapsed\n",
      "Epoch 44 [Train] loss:139.810 / [Valid] loss:129.321 , 14.29 minutes elapsed\n",
      "Epoch 45 [Train] loss:137.260 / [Valid] loss:133.543 , 14.61 minutes elapsed\n",
      "Epoch 46 [Train] loss:140.715 / [Valid] loss:156.146 , 14.93 minutes elapsed\n",
      "Epoch 47 [Train] loss:165.204 / [Valid] loss:128.423 , 15.25 minutes elapsed\n",
      "Epoch 48 [Train] loss:134.938 / [Valid] loss:141.870 , 15.57 minutes elapsed\n",
      "Epoch 49 [Train] loss:147.803 / [Valid] loss:131.492 , 15.90 minutes elapsed\n",
      "Epoch 50 [Train] loss:137.188 / [Valid] loss:123.740 , 16.23 minutes elapsed\n",
      "Epoch 51 [Train] loss:129.922 / [Valid] loss:128.711 , 16.55 minutes elapsed\n",
      "Epoch 52 [Train] loss:135.267 / [Valid] loss:127.788 , 16.87 minutes elapsed\n",
      "Epoch 53 [Train] loss:134.163 / [Valid] loss:121.618 , 17.19 minutes elapsed\n",
      "Epoch 54 [Train] loss:127.482 / [Valid] loss:121.150 , 17.52 minutes elapsed\n",
      "Epoch 55 [Train] loss:126.542 / [Valid] loss:122.990 , 17.84 minutes elapsed\n",
      "Epoch 56 [Train] loss:128.193 / [Valid] loss:121.044 , 18.17 minutes elapsed\n",
      "Epoch 57 [Train] loss:126.226 / [Valid] loss:117.643 , 18.49 minutes elapsed\n",
      "Epoch 58 [Train] loss:122.817 / [Valid] loss:116.890 , 18.81 minutes elapsed\n",
      "Epoch 59 [Train] loss:121.858 / [Valid] loss:117.568 , 19.13 minutes elapsed\n",
      "Epoch 60 [Train] loss:122.278 / [Valid] loss:116.087 , 19.45 minutes elapsed\n",
      "Epoch 61 [Train] loss:120.536 / [Valid] loss:114.098 , 19.77 minutes elapsed\n",
      "Epoch 62 [Train] loss:118.263 / [Valid] loss:113.978 , 20.10 minutes elapsed\n",
      "Epoch 63 [Train] loss:117.869 / [Valid] loss:114.083 , 20.43 minutes elapsed\n",
      "Epoch 64 [Train] loss:117.723 / [Valid] loss:112.849 , 20.75 minutes elapsed\n",
      "Epoch 65 [Train] loss:116.351 / [Valid] loss:111.629 , 21.10 minutes elapsed\n",
      "Epoch 66 [Train] loss:115.124 / [Valid] loss:111.573 , 21.42 minutes elapsed\n",
      "Epoch 67 [Train] loss:115.014 / [Valid] loss:110.961 , 21.75 minutes elapsed\n",
      "Epoch 68 [Train] loss:114.294 / [Valid] loss:109.586 , 22.06 minutes elapsed\n",
      "Epoch 69 [Train] loss:112.777 / [Valid] loss:109.233 , 22.39 minutes elapsed\n",
      "Epoch 70 [Train] loss:112.314 / [Valid] loss:108.738 , 22.71 minutes elapsed\n",
      "Epoch 71 [Train] loss:111.831 / [Valid] loss:107.365 , 23.05 minutes elapsed\n",
      "Epoch 72 [Train] loss:110.465 / [Valid] loss:106.853 , 23.39 minutes elapsed\n",
      "Epoch 73 [Train] loss:109.877 / [Valid] loss:105.813 , 23.76 minutes elapsed\n",
      "Epoch 74 [Train] loss:108.803 / [Valid] loss:104.849 , 24.10 minutes elapsed\n",
      "Epoch 75 [Train] loss:107.921 / [Valid] loss:104.067 , 24.42 minutes elapsed\n",
      "Epoch 76 [Train] loss:107.095 / [Valid] loss:103.298 , 24.75 minutes elapsed\n",
      "Epoch 77 [Train] loss:106.133 / [Valid] loss:102.896 , 25.09 minutes elapsed\n",
      "Epoch 78 [Train] loss:105.603 / [Valid] loss:102.249 , 25.42 minutes elapsed\n",
      "Epoch 79 [Train] loss:104.825 / [Valid] loss:101.816 , 25.75 minutes elapsed\n",
      "Epoch 80 [Train] loss:104.230 / [Valid] loss:101.150 , 26.11 minutes elapsed\n",
      "Epoch 81 [Train] loss:103.455 / [Valid] loss:100.311 , 26.44 minutes elapsed\n",
      "Epoch 82 [Train] loss:102.588 / [Valid] loss:99.358 , 26.76 minutes elapsed\n",
      "Epoch 83 [Train] loss:101.573 / [Valid] loss:98.351 , 27.08 minutes elapsed\n",
      "Epoch 84 [Train] loss:100.517 / [Valid] loss:97.585 , 27.40 minutes elapsed\n",
      "Epoch 85 [Train] loss:99.657 / [Valid] loss:97.250 , 27.73 minutes elapsed\n",
      "Epoch 86 [Train] loss:99.113 / [Valid] loss:96.982 , 28.04 minutes elapsed\n",
      "Epoch 87 [Train] loss:98.485 / [Valid] loss:96.839 , 28.36 minutes elapsed\n",
      "Epoch 88 [Train] loss:97.956 / [Valid] loss:96.629 , 28.68 minutes elapsed\n",
      "Epoch 89 [Train] loss:97.459 / [Valid] loss:96.264 , 29.01 minutes elapsed\n",
      "Epoch 90 [Train] loss:96.867 / [Valid] loss:95.882 , 29.33 minutes elapsed\n",
      "Epoch 91 [Train] loss:96.314 / [Valid] loss:95.514 , 29.66 minutes elapsed\n",
      "Epoch 92 [Train] loss:95.664 / [Valid] loss:95.347 , 29.98 minutes elapsed\n",
      "Epoch 93 [Train] loss:95.119 / [Valid] loss:95.038 , 30.30 minutes elapsed\n",
      "Epoch 94 [Train] loss:94.533 / [Valid] loss:94.975 , 30.62 minutes elapsed\n",
      "Epoch 95 [Train] loss:94.193 / [Valid] loss:95.101 , 30.95 minutes elapsed\n",
      "Epoch 96 [Train] loss:94.449 / [Valid] loss:98.189 , 31.27 minutes elapsed\n",
      "Epoch 97 [Train] loss:96.581 / [Valid] loss:95.197 , 31.59 minutes elapsed\n",
      "Epoch 98 [Train] loss:93.614 / [Valid] loss:94.279 , 31.91 minutes elapsed\n",
      "Epoch 99 [Train] loss:92.403 / [Valid] loss:95.484 , 32.23 minutes elapsed\n",
      "Epoch 100 [Train] loss:93.449 / [Valid] loss:93.511 , 32.57 minutes elapsed\n",
      "Result: best valid loss 93.511\n"
     ]
    }
   ],
   "source": [
    "Encoder_bi_lstm = False\n",
    "encoder_hidden_size = 512\n",
    "decoder_multiplier = 2 if Encoder_bi_lstm else 1\n",
    "encoder_config = {\n",
    "    \"rnn_num_layers\": 1,\n",
    "    \"input_feature_len\": 13, #tunable\n",
    "    \"sequence_len\": 8,\n",
    "    \"hidden_size\": encoder_hidden_size, #tunable\n",
    "    \"bidirectional\": Encoder_bi_lstm\n",
    "}\n",
    "\n",
    "decoder_attention_config = {\n",
    "    \"input_feature_len\": 1,\n",
    "    \"hidden_size\": encoder_hidden_size * decoder_multiplier, #tunable\n",
    "    \"sequence_len\": 8 \n",
    "}\n",
    "\n",
    "Encoder = RNNEncoder(**encoder_config)\n",
    "AttentionDecoder = AttentionDecoderCell(**decoder_attention_config)\n",
    "Encoder.apply(init_weights)\n",
    "AttentionDecoder.apply(init_weights)\n",
    "\n",
    "optimizer_name = \"Adam\"\n",
    "lr = 0.005\n",
    "patience = 100\n",
    "\n",
    "encoder_optimizer = getattr(optim, optimizer_name)(Encoder.parameters(), lr=lr)\n",
    "decoder_optimizer = getattr(optim, optimizer_name)(AttentionDecoder.parameters(), lr=lr)\n",
    "predict_time_steps = 8\n",
    "teacher_forcing_prob = 0\n",
    "criterion = torch.nn.MSELoss(reduction = \"sum\")\n",
    "\n",
    "NUM_EPOCH = 100\n",
    "best_encoder, best_decoder = run_training(\n",
    "    train_loader, valid_loader, Encoder, AttentionDecoder, patience,\n",
    "    NUM_EPOCH, encoder_optimizer, decoder_optimizer, criterion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL_DIR = \"./best/b06702064_ShengYen-Lin.pth\"\n",
    "CSV_SAVE_DIR = \"./best/submission.csv\"\n",
    "torch.save({'encoder': best_encoder, 'attentionDecoder': best_decoder}, SAVE_MODEL_DIR)\n",
    "run_testing(test_loader, best_encoder, best_decoder, device, CSV_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 8\n",
    "\n",
    "X_train = np.load('./data/training_x.npy')\n",
    "X_test = np.load('./data/testing_x.npy')\n",
    "y_train = np.load('./data/training_y.npy')\n",
    "\n",
    "SS = StandardScaler()\n",
    "X_train_norm = SS.fit_transform(X_train)\n",
    "X_test_norm = SS.transform(X_test)\n",
    "X_test_shift = make_data(X_test_norm, timestep, data_type = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "test_dataset = WeatherDataset(\n",
    "    X_test_shift, None, \"test\"\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size, shuffle = False\n",
    ")\n",
    "\n",
    "DUMMY_INPUT = torch.tensor(\n",
    "    y_train.mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL_DIR = \"./best/b06702064_ShengYen-Lin.pth\"\n",
    "CSV_SAVE_DIR = \"./best/submission.csv\"\n",
    "checkpoint = torch.load(SAVE_MODEL_DIR)\n",
    "best_Encoder = checkpoint[\"encoder\"]\n",
    "best_AttentionDecoder = checkpoint[\"attentionDecoder\"]\n",
    "run_testing(test_loader, best_Encoder, best_AttentionDecoder, timestep, device, CSV_SAVE_DIR)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
